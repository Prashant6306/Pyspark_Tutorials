{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sophisticated-albany",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T16:36:03.852428Z",
     "iopub.status.busy": "2023-04-28T16:36:03.851098Z",
     "iopub.status.idle": "2023-04-28T16:36:52.095432Z",
     "shell.execute_reply": "2023-04-28T16:36:52.094579Z",
     "shell.execute_reply.started": "2023-04-27T17:38:20.804391Z"
    },
    "papermill": {
     "duration": 48.257495,
     "end_time": "2023-04-28T16:36:52.095634",
     "exception": false,
     "start_time": "2023-04-28T16:36:03.838139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 310.8 MB 8.0 kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.9.7\r\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 200 kB 56.7 MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=0d834d9311d99531698d6183c281f46d86949a0d6b5117b3007e94ac8490a21e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/51/98/f7a41aad64c08302d6c26c90650e713c3dfeb5cdec4946db00\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-administrator",
   "metadata": {
    "papermill": {
     "duration": 0.140704,
     "end_time": "2023-04-28T16:36:52.379170",
     "exception": false,
     "start_time": "2023-04-28T16:36:52.238466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# from pyspark.sql import SparkSession. \n",
    "# \n",
    "The line of code \"from pyspark.sql import SparkSession\" is used to import the SparkSession module from the pyspark.sql package in PySpark.\n",
    "\n",
    "SparkSession is the entry point to programming Spark with the DataFrame and Dataset APIs. It allows you to create a Spark application and provides a way to interact with Spark. You can use SparkSession to create DataFrame and Dataset objects, register DataFrames as tables, cache tables, and execute SQL queries on them.\n",
    "\n",
    "The \"import\" statement makes the SparkSession module available in your Python code, allowing you to use its functionality. Once you have imported SparkSession, you can create a SparkSession object and start working with Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-sender",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T16:36:52.656322Z",
     "iopub.status.busy": "2023-04-28T16:36:52.655632Z",
     "iopub.status.idle": "2023-04-28T16:36:52.728204Z",
     "shell.execute_reply": "2023-04-28T16:36:52.727509Z",
     "shell.execute_reply.started": "2023-04-27T17:39:00.794323Z"
    },
    "papermill": {
     "duration": 0.211268,
     "end_time": "2023-04-28T16:36:52.728380",
     "exception": false,
     "start_time": "2023-04-28T16:36:52.517112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "czech-ridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T16:36:53.011265Z",
     "iopub.status.busy": "2023-04-28T16:36:53.010587Z",
     "iopub.status.idle": "2023-04-28T16:36:53.015089Z",
     "shell.execute_reply": "2023-04-28T16:36:53.015615Z",
     "shell.execute_reply.started": "2023-04-27T17:39:00.858850Z"
    },
    "papermill": {
     "duration": 0.145018,
     "end_time": "2023-04-28T16:36:53.015796",
     "exception": false,
     "start_time": "2023-04-28T16:36:52.870778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabulous-vessel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T16:36:53.294768Z",
     "iopub.status.busy": "2023-04-28T16:36:53.293882Z",
     "iopub.status.idle": "2023-04-28T16:37:06.489614Z",
     "shell.execute_reply": "2023-04-28T16:37:06.488185Z",
     "shell.execute_reply.started": "2023-04-27T17:39:00.863881Z"
    },
    "papermill": {
     "duration": 13.339227,
     "end_time": "2023-04-28T16:37:06.489840",
     "exception": false,
     "start_time": "2023-04-28T16:36:53.150613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|dob       |gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|James    |          |Smith   |1991-04-01|M     |3000  |\n",
      "|Michael  |Rose      |        |2000-05-19|M     |4000  |\n",
      "|Robert   |          |Williams|1978-09-05|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark =SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data =[('James','','Smith','1991-04-01','M',3000),\n",
    "('Michael','Rose','','2000-05-19','M',4000),\n",
    "('Robert','','Williams','1978-09-05','M',4000),\n",
    "('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns =[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns) \n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-warner",
   "metadata": {
    "papermill": {
     "duration": 0.15137,
     "end_time": "2023-04-28T16:37:06.794070",
     "exception": false,
     "start_time": "2023-04-28T16:37:06.642700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 72.972036,
   "end_time": "2023-04-28T16:37:08.356296",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-28T16:35:55.384260",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
